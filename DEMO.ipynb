{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-SAT: DETECTING COMPANY REFERENCES IN THE PRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from tools.utility import *\n",
    "from articleClassifier import ArticleClassifier \n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Tokenized Cleaned Corpus of Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenized Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/corpus/\"\n",
    "file = \"cleaned_tokenized_corpus\"\n",
    "with open(PATH + file +\".json\") as json_file: \n",
    "    article_corpus = json.load(json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of articles per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count = dict()\n",
    "for document in article_corpus:\n",
    "    labels = document[\"siren\"]\n",
    "    for siren in labels:\n",
    "        if siren in dict_count.keys():\n",
    "            dict_count[siren] +=1\n",
    "        else:\n",
    "            dict_count[siren] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List companies with more than N articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1501 companies with MORE than 5 associated articles\n"
     ]
    }
   ],
   "source": [
    "n_associated_articles = 5\n",
    "siren_filtered =[key for key in dict_count if dict_count[key] > n_associated_articles]\n",
    "print (\"There are\",len(siren_filtered),\"companies with MORE than\",n_associated_articles,\"associated articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Corpus into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels removed: 0\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train_corpus, X_test_corpus = train_test_split(corpus, test_size=test_size, random_state=0)\n",
    "X_test_corpus = clean_corpus_labels (X_test_corpus, siren_filtered) # Removing labels we are not considering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Scored Relevant Words from dictionnairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION 1: generate the relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = X_train_corpus     # corpus\n",
    "list_siren = siren_filtered # companies kept for the study\n",
    "relevant_words_tfidf = generate_relevant_words_tfidf(corpus,list_siren)\n",
    "#100%|██████████| 1501/1501 [1:21:23<00:00,  2.34s/it] # nouns sublinear_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION 2: load pre-generated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rw_tfidf_sublinear_tf_1501_companies is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# load dictionary \n",
    "PATH = \"./data/relevant_words/\"\n",
    "file = \"rw_tfidf_sublinear_tf_1501_companies\"\n",
    "a_file = open(PATH + file + \".json\", \"r\")\n",
    "relevant_words_tfidf = json.load(a_file)\n",
    "print (file,\"is loaded successfully\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Companies of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "related_words = relevant_words_tfidf #model related words\n",
    "corpus = X_test_corpus[:1000]\n",
    "#corpus = X_test_corpus\n",
    "min_score = 0.9\n",
    "n_sig_words = 3\n",
    "t = 250\n",
    "max_n_pred = None\n",
    "criterion = \"T\"\n",
    "\n",
    "# FIT and PREDICT of ArticleClassifier model\n",
    "ac_model = ArticleClassifier(n_sig_words,min_score ,t) # Init Article Classifier \n",
    "ac_model.fit(related_words)    # fit related words\n",
    "predictions = ac_model.predict(corpus,max_n_pred, criterion) # evaluate corpus\n",
    "print (\"Predictions on Test Set Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_model.evaluate()\n",
    "ac_model.print_eval(verbose = 2) # verbose = 0,1,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrations on ArticleClassifier functionnalities.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
